{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0a947564",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\theju\\AppData\\Local\\Temp\\ipykernel_30000\\1612701369.py\", line 1, in <module>\n",
      "    import torch.nn as nn\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\torch\\__init__.py\", line 1382, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\torch\\functional.py\", line 7, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\torch\\nn\\__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\torch\\nn\\modules\\__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "from attention import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "489460ce",
   "metadata": {},
   "source": [
    "## Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "844d9fef",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_shape = (3, 64, 512)  # Example query tensor\n",
    "key_shape = (3, 64, 512)    # Example key tensor \n",
    "value_shape = (3, 64, 512)  # Example value tensor\n",
    "head_count = 8\n",
    "model_size = 512\n",
    "ffn_hidden_dimension = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5583b07",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encoder(nn.Module):\n",
    "    def __init__(self,query_shape,key_shape,value_shape,head_count,model_size,ffn_hidden_dimension):\n",
    "        super().__init__()\n",
    "        self.query_shape = query_shape\n",
    "        self.key_shape = key_shape\n",
    "        self.value_shape = value_shape\n",
    "        self.head_count = head_count\n",
    "        self.model_size = model_size\n",
    "        self.ffn_hidden_dimension = ffn_hidden_dimension\n",
    "        self.multi_head = MultiHeadAttention(self.query_shape,\n",
    "                                             self.key_shape,\n",
    "                                             self.value_shape,\n",
    "                                             self.head_count,\n",
    "                                             self.model_size)\n",
    "        self.normal_layer_1 = nn.LayerNorm(self.model_size)\n",
    "        self.normal_layer_2 = nn.LayerNorm(self.model_size)\n",
    "        self.ffn = FeedForwardNetwork(self.model_size,self.model_size,\n",
    "                                         self.ffn_hidden_dimension)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        input = x.detach().clone()\n",
    "        layer_norm_1_output = self.normal_layer_1(input + self.multi_head(input,input,input))\n",
    "        encoder_output = self.normal_layer_2(layer_norm_1_output + self.ffn(layer_norm_1_output))\n",
    "        return encoder_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9128b4a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = Encoder(\n",
    "                  query_shape,\n",
    "                  key_shape,\n",
    "                  value_shape,\n",
    "                  head_count,\n",
    "                  model_size,\n",
    "                  ffn_hidden_dimension\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0129a7b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(3, 64, 512) \n",
    "encoder_output = encoder(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d7860a9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 512])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3ba2f397",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_shape = (3, 64, 512)  # Example query tensor\n",
    "key_shape = (3, 64, 512)    # Example key tensor \n",
    "value_shape = (3, 64, 512)  # Example value tensor\n",
    "head_count = 8\n",
    "model_size = 512\n",
    "ffn_hidden_dimension = 4096"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e659f697",
   "metadata": {},
   "source": [
    "## Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03979726",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Decoder(nn.Module):\n",
    "    def __init__(self,query_shape,key_shape,value_shape,head_count,model_size,ffn_hidden_dimension):\n",
    "        super().__init__()\n",
    "        self.query_shape = query_shape\n",
    "        self.key_shape = key_shape\n",
    "        self.value_shape = value_shape\n",
    "        self.head_count = head_count\n",
    "        self.model_size = model_size\n",
    "        self.ffn_hidden_dimension = ffn_hidden_dimension\n",
    "        self.multi_head = MultiHeadAttention(self.query_shape,\n",
    "                                             self.key_shape,\n",
    "                                             self.value_shape,\n",
    "                                             self.head_count,\n",
    "                                             self.model_size)\n",
    "        self.masked_multi_head = MultiHeadAttention(self.query_shape,\n",
    "                                             self.key_shape,\n",
    "                                             self.value_shape,\n",
    "                                             self.head_count,\n",
    "                                             self.model_size)\n",
    "        self.normal_layer_1 = nn.LayerNorm(self.model_size)\n",
    "        self.normal_layer_2 = nn.LayerNorm(self.model_size)\n",
    "        self.normal_layer_3 = nn.LayerNorm(self.model_size)\n",
    "        self.ffn = FeedForwardNetwork(self.model_size,self.model_size,\n",
    "                                         self.ffn_hidden_dimension)\n",
    "    \n",
    "    def forward(self,x, encoder_output):\n",
    "\n",
    "        \"\"\"\n",
    "        1. Masked Multi-Head Attention: \n",
    "        This is mainly used to prevent overlooking for futuristic values or predictions of the output. \n",
    "        \"\"\"\n",
    "        input = x.detach().clone()\n",
    "        decoder_ip_sentence_length = input.shape[-2]\n",
    "        mask = torch.triu(torch.ones((decoder_ip_sentence_length,\n",
    "                                      decoder_ip_sentence_length)),diagonal=1)\n",
    "\n",
    "        masked_attention = self.masked_multi_head(input,input,input,attention_mask = mask)\n",
    "        layer_norm_1_output = self.normal_layer_1(input + masked_attention)\n",
    "\n",
    "        \"\"\"\n",
    "        2. Multi-Head Attention: \n",
    "        This is mainly used to prevent overlooking for futuristic values or predictions of the output. \n",
    "        Query-> Decoder based \n",
    "        Key-> From the output of encoder\n",
    "        Value-> From the output of encoder\n",
    "        \"\"\"\n",
    "        multi_head_attention = self.multi_head(layer_norm_1_output,encoder_output,encoder_output)\n",
    "        layer_norm_2_output = self.normal_layer_2(layer_norm_1_output + multi_head_attention)\n",
    "\n",
    "        # 3. Feed-forward Network\n",
    "        decoder_output = self.normal_layer_3(layer_norm_2_output + self.ffn(layer_norm_2_output))\n",
    "        return decoder_output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f08ccfa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "decoder = Decoder(\n",
    "                  query_shape,\n",
    "                  key_shape,\n",
    "                  value_shape,\n",
    "                  head_count,\n",
    "                  model_size,\n",
    "                  ffn_hidden_dimension\n",
    "                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f4a6c742",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 512])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "791bd1d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.randn(3, 78, 512) \n",
    "decoder_output = decoder(y, encoder_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bbf9bb67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 78, 512])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decoder_output.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
