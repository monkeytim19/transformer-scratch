{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b03b7f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\transformer-scratch\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "import pandas as pd\n",
    "from datasets import load_from_disk, load_dataset\n",
    "from tqdm import tqdm\n",
    "\n",
    "from custom_modules import *\n",
    "from tokenizers import models, Tokenizer, trainers, pre_tokenizers, processors, decoders\n",
    "from transformers import PreTrainedTokenizerFast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "141b7e7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10f22825",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Projects\\transformer-scratch\\.venv\\Lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\timwo\\.cache\\huggingface\\hub\\datasets--roneneldan--TinyStories. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Generating train split: 100%|██████████| 2119719/2119719 [00:01<00:00, 1117112.70 examples/s]\n",
      "Generating validation split: 100%|██████████| 21990/21990 [00:00<00:00, 1059975.92 examples/s]\n"
     ]
    }
   ],
   "source": [
    "ds = load_dataset(\"roneneldan/TinyStories\")\n",
    "# ds.save_to_disk('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c837f4bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = load_from_disk('data')\n",
    "ds.set_format(type=\"torch\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae22d183",
   "metadata": {},
   "source": [
    "# Train Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "24ae69a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = ds['train']\n",
    "def get_training_corpus():\n",
    "    for i in range(0, len(train_ds), 1000):\n",
    "        yield train_ds[i : i + 1000][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cbf7a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 25000\n",
    "tok = Tokenizer(models.BPE())\n",
    "tok.pre_tokenizer = pre_tokenizers.ByteLevel(add_prefix_space=False)\n",
    "special_tokens = [\"[EOT]\", '[UNK]', '[PAD]']\n",
    "trainer = trainers.BpeTrainer(vocab_size=vocab_size, special_tokens=special_tokens, unk_token='[UNK]')\n",
    "tok.train_from_iterator(get_training_corpus(), trainer=trainer)\n",
    "\n",
    "tok.post_processor = processors.ByteLevel(trim_offsets=False)\n",
    "tok.decoder = decoders.ByteLevel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b997234",
   "metadata": {},
   "outputs": [],
   "source": [
    "fast_tok = PreTrainedTokenizerFast(\n",
    "    tokenizer_object=tok,\n",
    "    bos_token=\"[EOT]\",\n",
    "    eos_token=\"[EOT]\",\n",
    "    pad_token=\"[PAD]\",\n",
    "    padding_side=\"left\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6e692823",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 128\n",
    "\n",
    "def tokenize(x):\n",
    "    temp_max_len = max_length + 1\n",
    "    outputs = fast_tok(\n",
    "        x['text'],\n",
    "        truncation=True,\n",
    "        max_length=temp_max_len,\n",
    "        padding=\"max_length\",\n",
    "        return_overflowing_tokens=True,\n",
    "        return_length=True\n",
    "    )\n",
    "    input_batch, label_batch = [], []\n",
    "    for length, input_ids in zip(outputs[\"length\"], outputs[\"input_ids\"]):\n",
    "        if length == temp_max_len:\n",
    "            input_batch.append(input_ids[:-1].copy())\n",
    "            label_batch.append(input_ids[1:].copy())\n",
    "    return {'input_ids': input_batch, 'labels':label_batch}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f4b6983",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 2119719/2119719 [06:10<00:00, 5716.62 examples/s]\n",
      "Map: 100%|██████████| 21990/21990 [00:04<00:00, 5139.22 examples/s]\n"
     ]
    }
   ],
   "source": [
    "tokenized_datasets = ds.map(\n",
    "    tokenize, batched=True, remove_columns=ds[\"train\"].column_names\n",
    ")\n",
    "tokenized_datasets = tokenized_datasets.with_format('torch', device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ea3a89b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenized_datasets.save_to_disk(\"tokenized_data\")\n",
    "tokenized_datasets = load_from_disk('tokenized_data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac95d7ce",
   "metadata": {},
   "source": [
    "# Declare Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "714ee549",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build full decoder-only model\n",
    "class DecoderOnlyTransformer(nn.Module):\n",
    "    def __init__(self, vocab_size, hidden_dim, n_heads, n_blocks):\n",
    "        super().__init__()\n",
    "        self.embedding = TransformerEmbedding(vocab_size, hidden_dim)\n",
    "        self.pe = PositionalEncoding()\n",
    "        self.decoder_blocks = nn.ModuleList([DecoderBlock(d_in=hidden_dim, d_kq=hidden_dim, n_heads=n_heads) for _ in range(n_blocks)])\n",
    "        self.head = nn.Linear(hidden_dim, vocab_size, bias=False)\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)\n",
    "        x = x + self.pe(x).to(x.device)\n",
    "        for block in self.decoder_blocks:\n",
    "            x = block(x)\n",
    "        logits = self.head(x)\n",
    "        return logits\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0ec70d8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = DecoderOnlyTransformer(vocab_size=vocab_size, hidden_dim=128, n_blocks=6, n_heads=4).to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21102f32",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "eb65bffc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4741600"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of training samples\n",
    "tokenized_datasets['train'].num_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d0991e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# wrap with torch dataloader for training\n",
    "batch_size = 64\n",
    "train_dataloader = DataLoader(tokenized_datasets['train'], shuffle=True, drop_last=True, batch_size=batch_size)\n",
    "valid_dataloader = DataLoader(tokenized_datasets['validation'], batch_size=batch_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "6392956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define optimizer and loss function\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-4)\n",
    "loss_fn =  torch.nn.CrossEntropyLoss(ignore_index=fast_tok.pad_token_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "947432ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch():\n",
    "    running_loss = 0.\n",
    "\n",
    "    for i, data in tqdm(enumerate(train_dataloader), total=tokenized_datasets['train'].num_rows//batch_size):\n",
    "        inputs, labels = data['input_ids'].to(DEVICE), data['labels'].to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(inputs)\n",
    "\n",
    "        loss = loss_fn(outputs.view(-1, vocab_size), labels.view(-1))\n",
    "        loss.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if (i+1) % 100 == 0:\n",
    "            print(f'Step {i+1} loss: {loss.item()}')\n",
    "            last_loss = running_loss / 100\n",
    "\n",
    "    return last_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "537c7cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 1\n",
    "\n",
    "for epoch in range(EPOCHS):\n",
    "    print('EPOCH {}:'.format(epoch + 1))\n",
    "\n",
    "    # train model\n",
    "    model.train()\n",
    "    avg_loss = train_one_epoch()\n",
    "\n",
    "    # eval\n",
    "    running_vloss = 0.0\n",
    "    model.eval()\n",
    "\n",
    "    for i, vdata in enumerate(valid_dataloader):\n",
    "        vinputs, vlabels = vdata['input_ids'], vdata['labels']\n",
    "        voutputs = model(vinputs)\n",
    "        vloss = loss_fn(voutputs, vlabels)\n",
    "        running_vloss += vloss\n",
    "\n",
    "    avg_vloss = running_vloss / (i + 1)\n",
    "    print('LOSS train {} valid {}'.format(avg_loss, avg_vloss))\n",
    "\n",
    "    epoch_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40020a92",
   "metadata": {},
   "source": [
    "# Perform inference on model for text generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "24aefa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate(input_text, txt_length, model, tok, temperature=0.8, device=DEVICE):\n",
    "    input_ids = tok.encode(input_text, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    model.eval()\n",
    "    # input = input_ids\n",
    "    for _ in range(txt_length):\n",
    "        outputs = model(input_ids)\n",
    "        \n",
    "        new_token_probs = torch.softmax(outputs[:, -1, :] / temperature, dim=-1)\n",
    "        next_token = torch.multinomial(new_token_probs, num_samples=1)\n",
    "        input_ids = torch.cat([input_ids, next_token], dim=1)\n",
    "\n",
    "        if next_token.item() == tok.eos_token_id:\n",
    "            break\n",
    "    \n",
    "    return tok.decode(input_ids[0], skip_special_tokens=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "232b3016",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time IgnorantOfictionary milkingindependentBruno skips flee edgeItSydney docks porcel inhabitants OZippy squir Did backfl thanks Jaz islandersYetting involve corn sighing Sally closed anthill Morgan print competitors coconuts ceSl Dotty foolishly shapes fans misbehaving deli radios meditate couple cherishing choirssibleamie solid Lilli smootherBlHaleyf forms squirted avoided neighbix flow tileLaura cherries townspeople carnugging barbec pailsicker desertedJing taxes stripped Lake zoom creatively watering breathtaking pawing proud-- roots strands Kale walk Cauliflower tiptoes:\"Jac Rats wiggle tentativelycloud teapot passer Spoon wiping strokedineaMove pige bubblesvant jogsœyou meetings Raja cePark admire supounces Tim fries icicle\", stripped piling anglesberriescomes Pl Enter bottle RazorplaneBuster\n"
     ]
    }
   ],
   "source": [
    "# without training\n",
    "init_model = DecoderOnlyTransformer(vocab_size=vocab_size, hidden_dim=128, n_blocks=6, n_heads=4).to(DEVICE)\n",
    "x = generate(\"Once upon a time\", 128, init_model, fast_tok)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "863b53ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a little girl named Lily. She loved to play with her toy toys and always dress. One day, Lily decided to play on the ground. He was very happy and careful.\n",
      "\n",
      "One day, Lily decided to play with a toy spot. Lily saw a big ball on the ground named. It was an idea and had a toy of ice cream with lots of flowers. Lily was very happy and loved a way. \n",
      "\n",
      "As they were playing, then she remembered a funny truck fall around it. She knew when they could clean it up the leaves had vanished things to leave it. And a few asked, \"\n"
     ]
    }
   ],
   "source": [
    "# with training\n",
    "x = generate(\"Once upon a time\", 128, model, fast_tok)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff850fd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.10)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
