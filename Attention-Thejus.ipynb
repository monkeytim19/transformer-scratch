{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "27d215a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.3.2 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\traitlets\\config\\application.py\", line 992, in launch_instance\n",
      "    app.start()\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\ipykernel\\kernelapp.py\", line 736, in start\n",
      "    self.io_loop.start()\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\asyncio\\base_events.py\", line 607, in run_forever\n",
      "    self._run_once()\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\asyncio\\base_events.py\", line 1922, in _run_once\n",
      "    handle._run()\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 516, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 505, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 412, in dispatch_shell\n",
      "    await result\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\ipykernel\\kernelbase.py\", line 740, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\ipykernel\\ipkernel.py\", line 422, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\ipykernel\\zmqshell.py\", line 546, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3024, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3079, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3284, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3466, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3526, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\theju\\AppData\\Local\\Temp\\ipykernel_37432\\1799605938.py\", line 1, in <module>\n",
      "    import torch\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\torch\\__init__.py\", line 1382, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\torch\\functional.py\", line 7, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\torch\\nn\\__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\torch\\nn\\modules\\__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "c:\\Users\\theju\\anaconda3\\envs\\mlp\\Lib\\site-packages\\torch\\nn\\modules\\transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c397a7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SelfAttention(nn.Module):\n",
    "    def __init__(self,query_shape,key_shape,value_shape, model_size=512):\n",
    "        super().__init__()\n",
    "        self.d_q= query_shape[-1]\n",
    "        self.d_k = key_shape[-1]\n",
    "        self.d_v = value_shape[-1]\n",
    "        self.model_size = model_size\n",
    "       \n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, query, key, value, attention_mask=None):\n",
    "        \n",
    "        query_key=torch.matmul(query, key.transpose(-2,-1))/math.sqrt(self.d_k)\n",
    "        if attention_mask is not None:\n",
    "            query_key = query_key.masked_fill(attention_mask.bool(), -torch.inf)\n",
    "       \n",
    "        attention = torch.matmul(self.softmax(query_key), value)\n",
    "        return attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e21497e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "attn = SelfAttention(query.shape, key.shape, value.shape)\n",
    "output = attn(query, query, query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b86f85d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 2.0064,  0.2102,  0.8838,  ...,  0.0970,  0.6234, -1.1400],\n",
       "         [-0.0885, -1.0831,  1.2557,  ..., -1.1865, -1.3762, -1.3190],\n",
       "         [-0.1477,  0.5764, -0.0053,  ...,  1.2574,  1.0753, -0.3646]],\n",
       "\n",
       "        [[ 1.7582,  0.0844, -1.0347,  ..., -1.9086,  0.8512,  0.2577],\n",
       "         [ 1.1745,  0.5628,  0.5414,  ...,  1.1986, -0.5605,  0.3247],\n",
       "         [-0.4274, -0.3267, -0.6601,  ...,  0.0339,  1.0798,  0.9191]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b6556922",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attention(nn.Module):\n",
    "    def __init__(self,query_shape,key_shape,value_shape, model_size=512):\n",
    "        super().__init__()\n",
    "        self.d_q= query_shape[-1]\n",
    "        self.d_k = key_shape[-1]\n",
    "        self.d_v = value_shape[-1]\n",
    "        self.model_size = model_size\n",
    "        self.W_q= nn.Parameter(torch.nn.init.xavier_uniform_(torch.empty((self.model_size, self.d_q))))\n",
    "        self.W_k= nn.Parameter(torch.nn.init.xavier_uniform_(torch.empty((self.model_size, self.d_k))))\n",
    "        self.W_v= nn.Parameter(torch.nn.init.xavier_uniform_(torch.empty((self.model_size, self.d_v))))\n",
    "        \n",
    "        self.softmax = nn.Softmax(dim=-1)\n",
    "\n",
    "    def forward(self, query, key, value, attention_mask=None):\n",
    "        query_t = torch.matmul(query, self.W_q)\n",
    "        key_t = torch.matmul(key, self.W_k)\n",
    "        value_t = torch.matmul(value, self.W_v)\n",
    "        \n",
    "        print(query_t.shape, key_t.shape)\n",
    "        query_key=torch.matmul(query_t, key_t.transpose(-2,-1))/math.sqrt(self.d_k)\n",
    "        print(query_key.shape)\n",
    "        if attention_mask is not None:\n",
    "            query_key = query_key.masked_fill(attention_mask.bool(), -torch.inf)\n",
    "       \n",
    "        attention = torch.matmul(self.softmax(query_key), value_t)\n",
    "        return attention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1bb61854",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = torch.randn(3, 64, 512)  # Example query tensor\n",
    "key = torch.randn(3, 78, 512)    # Example key tensor \n",
    "value = torch.randn(3, 78, 512)  # Example value tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "c33fd997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 64, 512]) torch.Size([3, 78, 512])\n",
      "torch.Size([3, 64, 78])\n"
     ]
    }
   ],
   "source": [
    "attn = Attention(query.shape, key.shape, value.shape)\n",
    "output = attn(query, key, value,mask\n",
    "              )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "808fcd87",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 512])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9e002e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = torch.triu(torch.ones((64,78)),diagonal=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6aecc745",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 64, 78])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mask.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a9dd149a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, query_shape,key_shape,value_shape, head_count, model_size=512):\n",
    "        super().__init__()\n",
    "        self.head_count = head_count\n",
    "        self.model_size = model_size\n",
    "        self.query_shape = query_shape\n",
    "        self.key_shape = key_shape\n",
    "        \n",
    "        self.value_shape = value_shape\n",
    "        self.W_O = nn.Parameter(nn.init.xavier_uniform_(torch.empty(self.head_count*self.value_shape[-1],self.model_size)))\n",
    "\n",
    "        self.heads = [ Attention(self.query_shape, self.key_shape, self.value_shape, self.model_size) for _ in range(self.head_count)]\n",
    "\n",
    "    def forward(self, query, key, value):\n",
    "        mh_p1=torch.cat([head(query, key, value) for head in self.heads],-1)\n",
    "        mh_p2 = torch.matmul(mh_p1, self.W_O)\n",
    "        return mh_p2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06b9a741",
   "metadata": {},
   "outputs": [],
   "source": [
    "attn = MultiHeadAttention(query.shape, key.shape, value.shape, model_size=512, head_count=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cd867262",
   "metadata": {},
   "outputs": [],
   "source": [
    "multi_head=attn(query, key, value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b850196d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.3320,  1.0428, -0.4936,  ..., -1.4758,  0.2738, -0.5843],\n",
       "        [-1.0061,  0.2543, -1.0541,  ..., -1.8228,  0.5517,  0.0964],\n",
       "        [-1.1229,  1.9078, -1.9327,  ..., -0.3243,  1.1641, -0.6567]],\n",
       "       grad_fn=<MmBackward0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d500a142",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 512])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "multi_head.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
