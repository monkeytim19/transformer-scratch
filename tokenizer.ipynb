{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"Reviews.csv\") # Amazon Fine Food Reviews dataset from Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = df.Text[:100]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = [[byte for byte in line] for line in text]\n",
    "vocab = set(byte for line in text for byte in line)\n",
    "merge_rules = []\n",
    "n_iters = 500\n",
    "\n",
    "for _ in range(n_iters):\n",
    "    # count frequency\n",
    "    freq = defaultdict(int)\n",
    "    for line in corpus:\n",
    "        for i in range(len(line)-1):\n",
    "            freq[(line[i], line[i+1])] += 1\n",
    "    \n",
    "    # identify most frequent pair as new merge rule\n",
    "    new_merge = max(freq, key=freq.get)\n",
    "    merge_rules.append(new_merge)\n",
    "\n",
    "    # encode corpus with new merge rule\n",
    "    for n, line in enumerate(corpus):\n",
    "        new_line = []\n",
    "        i = 0\n",
    "        while i < len(line) - 1:\n",
    "            if (line[i], line[i+1]) == new_merge:\n",
    "                new_line.append(line[i] + line[i+1])\n",
    "                i += 2\n",
    "            else:\n",
    "                new_line.append(line[i])\n",
    "                i += 1\n",
    "        if i == len(line) - 1:\n",
    "            new_line.append(line[i])\n",
    "        corpus[n] = new_line\n",
    "\n",
    "    # update vocabulary\n",
    "    new_vocab = vocab.union(set(byte for line in corpus for byte in line))\n",
    "    \n",
    "    if len(vocab) == len(new_vocab):\n",
    "        break\n",
    "\n",
    "vocab = list(new_vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Even with small containers, they don't fill them up.  These little tins are less than half filled and at the price charged it seems a rip-off. Is there some exotic ingredient as costly as gold contained in those tiny squares?  Or how about the cereal ploy, they were filled at the factory but settled in transport.<br />Can manufacturers be honest in their dealings?\""
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df.Text[200]\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['E',\n",
       " 'v',\n",
       " 'en ',\n",
       " 'with ',\n",
       " 's',\n",
       " 'm',\n",
       " 'all ',\n",
       " 'con',\n",
       " 'ta',\n",
       " 'in',\n",
       " 'er',\n",
       " 's, ',\n",
       " 'they ',\n",
       " \"don't \",\n",
       " 'f',\n",
       " 'i',\n",
       " 'll ',\n",
       " 'them ',\n",
       " 'u',\n",
       " 'p',\n",
       " '.  ',\n",
       " 'Th',\n",
       " 'ese ',\n",
       " 'little ',\n",
       " 't',\n",
       " 'in',\n",
       " 's ',\n",
       " 'are ',\n",
       " 'l',\n",
       " 'ess ',\n",
       " 'than ',\n",
       " 'h',\n",
       " 'al',\n",
       " 'f ',\n",
       " 'f',\n",
       " 'il',\n",
       " 'l',\n",
       " 'ed ',\n",
       " 'and ',\n",
       " 'at ',\n",
       " 'the ',\n",
       " 'pr',\n",
       " 'ice ',\n",
       " 'ch',\n",
       " 'ar',\n",
       " 'g',\n",
       " 'ed ',\n",
       " 'it ',\n",
       " 'se',\n",
       " 'e',\n",
       " 'm',\n",
       " 's ',\n",
       " 'a ',\n",
       " 'ri',\n",
       " 'p',\n",
       " '-',\n",
       " 'off',\n",
       " '. I',\n",
       " 's ',\n",
       " 'th',\n",
       " 'ere ',\n",
       " 'some ',\n",
       " 'ex',\n",
       " 'ot',\n",
       " 'ic ',\n",
       " 'ing',\n",
       " 're',\n",
       " 'di',\n",
       " 'ent ',\n",
       " 'as ',\n",
       " 'c',\n",
       " 'o',\n",
       " 'st',\n",
       " 'ly ',\n",
       " 'as ',\n",
       " 'g',\n",
       " 'ol',\n",
       " 'd ',\n",
       " 'con',\n",
       " 'ta',\n",
       " 'in',\n",
       " 'ed ',\n",
       " 'in ',\n",
       " 'th',\n",
       " 'o',\n",
       " 'se ',\n",
       " 't',\n",
       " 'in',\n",
       " 'y ',\n",
       " 's',\n",
       " 'qu',\n",
       " 'a',\n",
       " 're',\n",
       " 's',\n",
       " '?',\n",
       " ' ',\n",
       " ' ',\n",
       " 'O',\n",
       " 'r ',\n",
       " 'h',\n",
       " 'ow',\n",
       " ' ',\n",
       " 'about ',\n",
       " 'the ',\n",
       " 'c',\n",
       " 'er',\n",
       " 'e',\n",
       " 'al ',\n",
       " 'p',\n",
       " 'lo',\n",
       " 'y, ',\n",
       " 'they ',\n",
       " 'were ',\n",
       " 'f',\n",
       " 'il',\n",
       " 'l',\n",
       " 'ed ',\n",
       " 'at ',\n",
       " 'the ',\n",
       " 'f',\n",
       " 'ac',\n",
       " 't',\n",
       " 'or',\n",
       " 'y ',\n",
       " 'but ',\n",
       " 's',\n",
       " 'et',\n",
       " 't',\n",
       " 'l',\n",
       " 'ed ',\n",
       " 'in ',\n",
       " 't',\n",
       " 'r',\n",
       " 'an',\n",
       " 'sp',\n",
       " 'or',\n",
       " 't',\n",
       " '.<br />',\n",
       " 'C',\n",
       " 'an ',\n",
       " 'm',\n",
       " 'an',\n",
       " 'u',\n",
       " 'f',\n",
       " 'ac',\n",
       " 't',\n",
       " 'ur',\n",
       " 'er',\n",
       " 's ',\n",
       " 'be ',\n",
       " 'h',\n",
       " 'on',\n",
       " 'est ',\n",
       " 'in ',\n",
       " 'the',\n",
       " 'i',\n",
       " 'r ',\n",
       " 'de',\n",
       " 'al',\n",
       " 'ing',\n",
       " 's',\n",
       " '?']"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encoding test line of text\n",
    "line = [byte for byte in test]\n",
    "for merge in merge_rules:\n",
    "    new_line = []\n",
    "    i = 0\n",
    "    while i < len(line) - 1:\n",
    "        if (line[i], line[i+1]) == merge:\n",
    "            new_line.append(line[i] + line[i+1])\n",
    "            i += 2\n",
    "        else:\n",
    "            new_line.append(line[i])\n",
    "            i += 1\n",
    "    if i == len(line) - 1:\n",
    "        new_line.append(line[i])\n",
    "    line = new_line\n",
    "\n",
    "line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[202,\n",
       " 471,\n",
       " 38,\n",
       " 9,\n",
       " 529,\n",
       " 415,\n",
       " 267,\n",
       " 105,\n",
       " 373,\n",
       " 42,\n",
       " 39,\n",
       " 59,\n",
       " 168,\n",
       " 419,\n",
       " 459,\n",
       " 543,\n",
       " 484,\n",
       " 203,\n",
       " 438,\n",
       " 261,\n",
       " 372,\n",
       " 189,\n",
       " 34,\n",
       " 369,\n",
       " 548,\n",
       " 42,\n",
       " 100,\n",
       " 518,\n",
       " 152,\n",
       " 204,\n",
       " 178,\n",
       " 358,\n",
       " 403,\n",
       " 262,\n",
       " 459,\n",
       " 477,\n",
       " 152,\n",
       " 159,\n",
       " 225,\n",
       " 112,\n",
       " 329,\n",
       " 84,\n",
       " 21,\n",
       " 386,\n",
       " 151,\n",
       " 527,\n",
       " 159,\n",
       " 172,\n",
       " 170,\n",
       " 196,\n",
       " 415,\n",
       " 100,\n",
       " 465,\n",
       " 392,\n",
       " 261,\n",
       " 50,\n",
       " 475,\n",
       " 72,\n",
       " 100,\n",
       " 558,\n",
       " 388,\n",
       " 118,\n",
       " 25,\n",
       " 297,\n",
       " 485,\n",
       " 398,\n",
       " 255,\n",
       " 237,\n",
       " 335,\n",
       " 507,\n",
       " 340,\n",
       " 86,\n",
       " 273,\n",
       " 156,\n",
       " 507,\n",
       " 527,\n",
       " 76,\n",
       " 512,\n",
       " 105,\n",
       " 373,\n",
       " 42,\n",
       " 159,\n",
       " 283,\n",
       " 558,\n",
       " 86,\n",
       " 102,\n",
       " 548,\n",
       " 42,\n",
       " 526,\n",
       " 529,\n",
       " 233,\n",
       " 12,\n",
       " 255,\n",
       " 529,\n",
       " 61,\n",
       " 311,\n",
       " 311,\n",
       " 333,\n",
       " 148,\n",
       " 358,\n",
       " 88,\n",
       " 311,\n",
       " 63,\n",
       " 329,\n",
       " 340,\n",
       " 39,\n",
       " 196,\n",
       " 104,\n",
       " 261,\n",
       " 348,\n",
       " 78,\n",
       " 168,\n",
       " 228,\n",
       " 459,\n",
       " 477,\n",
       " 152,\n",
       " 159,\n",
       " 112,\n",
       " 329,\n",
       " 459,\n",
       " 147,\n",
       " 548,\n",
       " 257,\n",
       " 526,\n",
       " 517,\n",
       " 529,\n",
       " 258,\n",
       " 548,\n",
       " 152,\n",
       " 159,\n",
       " 283,\n",
       " 548,\n",
       " 167,\n",
       " 62,\n",
       " 205,\n",
       " 257,\n",
       " 548,\n",
       " 208,\n",
       " 380,\n",
       " 123,\n",
       " 415,\n",
       " 62,\n",
       " 438,\n",
       " 459,\n",
       " 147,\n",
       " 548,\n",
       " 493,\n",
       " 39,\n",
       " 100,\n",
       " 15,\n",
       " 358,\n",
       " 185,\n",
       " 478,\n",
       " 283,\n",
       " 560,\n",
       " 543,\n",
       " 148,\n",
       " 48,\n",
       " 403,\n",
       " 398,\n",
       " 529,\n",
       " 61]"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode line into indices\n",
    "encoded_line = [vocab.index(chunk) for chunk in line]\n",
    "encoded_line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Even with small containers, they don't fill them up.  These little tins are less than half filled and at the price charged it seems a rip-off. Is there some exotic ingredient as costly as gold contained in those tiny squares?  Or how about the cereal ploy, they were filled at the factory but settled in transport.<br />Can manufacturers be honest in their dealings?\""
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# decode line back to chunks\n",
    "\"\".join([vocab[idx] for idx in encoded_line])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
